{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "import pathlib\n",
    "from annoy import AnnoyIndex\n",
    "from gensim.models import Word2Vec\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: ''\n",
      "tags:\n",
      "- covisit\n",
      "- word2vec\n",
      "description: ' '\n",
      "data_path: ../data/\n",
      "validation_path: ../data/local_validation/\n",
      "ranker_path: ../data/ranker/\n",
      "artifact_path: ../artifacts/\n",
      "debug: false\n",
      "local_validation: true\n",
      "word2vec: true\n",
      "train_file: train.parquet\n",
      "test_file: test.parquet\n",
      "test_labels_file: test_labels.parquet\n",
      "submission_path: submissions/\n",
      "submission_file: submission.csv\n",
      "model_path: ../models/\n",
      "curr_model_path: models/word2vec.model\n",
      "type_labels:\n",
      "  clicks: 0\n",
      "  carts: 1\n",
      "  orders: 2\n",
      "type_weight:\n",
      "  0: 0.5\n",
      "  1: 9\n",
      "  2: 0.5\n",
      "version: 1\n",
      "chunk_size: 200000\n",
      "random_state: 42\n",
      "fraction: 0.02\n",
      "n_top: 15\n",
      "n_top_clicks: 20\n",
      "n_samples: 50\n",
      "time_diff: 7 * 24 * 60 * 60\n",
      "one_week: 7 * 24 * 60 * 60\n",
      "vector_size: 100\n",
      "window: 5\n",
      "negative: 10\n",
      "workers: 12\n",
      "epochs: 2\n",
      "min_count: 5\n",
      "n_trees: 100\n",
      "n_recent: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27634/3638907509.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../conf\", job_name=\"features_app\")\n"
     ]
    }
   ],
   "source": [
    "initialize(config_path=\"../conf\", job_name=\"features_app\")\n",
    "config = compose(config_name=\"config\", overrides=[\n",
    "                                                    \"data_path=../data/\", \n",
    "                                                    \"validation_path=../data/local_validation/\", \n",
    "                                                    \"ranker_path=../data/ranker/\", \n",
    "                                                    \"artifact_path=../artifacts/\",\n",
    "                                                    \"model_path=../models/\",\n",
    "                                                    ]\n",
    "                                                )\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"Load data from parquet files.\"\"\"\n",
    "    if config.local_validation:\n",
    "        train = pl.read_parquet(config.validation_path + config.train_file)\n",
    "        # test = pl.read_parquet(config.validation_path + config.test_file)\n",
    "        test = pl.read_parquet(config.ranker_path + config.test_file) # for ranker model\n",
    "    else:\n",
    "        train = pl.read_parquet(config.data_path + config.train_file)\n",
    "        test = pl.read_parquet(config.data_path + config.test_file)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load word2vec model.\"\"\"\n",
    "    if not config.word2vec:\n",
    "        return None\n",
    "    print(\"Loading word2vec model...\")\n",
    "    model = Word2Vec.load(f\"{config.model_path}word2vec_windowl_{config.window}.model\")\n",
    "    print(\n",
    "        f\"Model loaded from path: {config.model_path}word2vec_windowl_{config.window}.model\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_index(model, n_trees=100) -> Tuple[AnnoyIndex, Dict[str, int]]:\n",
    "    \"\"\"Build index for word2vec model.\"\"\"\n",
    "    if config.word2vec:\n",
    "        print(\"Building index for word2vec model...\")\n",
    "        aid2idx = {aid: i for i, aid in enumerate(model.wv.index_to_key)}\n",
    "        index = AnnoyIndex(model.wv.vector_size, metric=\"euclidean\")\n",
    "        for idx in aid2idx.values():\n",
    "            index.add_item(idx, model.wv.vectors[idx])\n",
    "        index.build(n_trees=n_trees)\n",
    "        return index, aid2idx\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def load_combined_covisitation(type: str = \"clicks\") -> pd.DataFrame:\n",
    "    top_20 = pd.read_pickle(\n",
    "        f\"{config.data_path}top_20_{type}_v{config.version}.pkl\"\n",
    "    )\n",
    "    print(f\"Size of top_20_{type}:\", len(top_20))\n",
    "    return top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train and test data: (163955180, 4) (2127742, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train and test data:\", train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of top_20_clicks: 1813303\n"
     ]
    }
   ],
   "source": [
    "covisit_clicks = load_combined_covisitation(type=\"clicks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model...\n",
      "Model loaded from path: ../models/word2vec_windowl_5.model\n",
      "Building index for word2vec model...\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "index, aid2idx = build_index(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_index = model.wv.key_to_index\n",
    "vectors = model.wv.vectors\n",
    "\n",
    "# reduce dimensionality of vectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(vectors)\n",
    "vectors = pca.transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_word2vec_feature(aids):\n",
    "    \"\"\"Add mean word2vec feature to dataframe.\"\"\"\n",
    "    if config.word2vec and len(aids) == 0 or not config.word2vec:\n",
    "        return np.zeros(config.vector_size)\n",
    "    else:\n",
    "        return list(\n",
    "            np.mean(\n",
    "            [vectors[key_to_index[aid]] for aid in aids if aid in key_to_index], axis=0\n",
    "        ))\n",
    "\n",
    "\n",
    "# how many items (that user has already clicked) have recommended this item with their co-visitation matrix\n",
    "def apply_covisit_clicks_feature(aids):\n",
    "    covisit_recomms = [0] * len(aids)\n",
    "    window_start = 0\n",
    "    for idx, window_end in enumerate(range(len(aids))):\n",
    "        user_sequence = aids[window_start:window_end]\n",
    "        curr_aid = aids[window_end]\n",
    "        unique_aids = list(set(user_sequence))\n",
    "        covisit_count = sum(curr_aid in covisit_clicks[aid] for aid in unique_aids if aid in covisit_clicks)\n",
    "        covisit_recomms[idx] = covisit_count\n",
    "    assert len(covisit_recomms) == len(aids)\n",
    "    return covisit_recomms\n",
    "\n",
    "\n",
    "def explode_word2vec_to_columns(df):\n",
    "    df = df.to_pandas()\n",
    "    columns = [f'word2vec_feature_{i}' for i in range(10)]\n",
    "    word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
    "    word2vec_features.columns = columns\n",
    "    word2vec_features, df = pl.DataFrame(word2vec_features), pl.DataFrame(df)\n",
    "    df = pl.concat([df, word2vec_features], how='horizontal')\n",
    "    df = df.drop(columns=['word2vec_feature'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logspace averaged mean of the feature vecture\n",
    "def add_word2vec_feature(df):\n",
    "    return df.select(\n",
    "        [\n",
    "            pl.col(\"*\"),\n",
    "            pl.col([\"aid\"])\n",
    "            .apply(add_mean_word2vec_feature)\n",
    "            .list()\n",
    "            .over(\"session\")\n",
    "            .alias(\"word2vec_feature\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def add_covisit_clicks_feature(df):\n",
    "    return df.select(\n",
    "        [\n",
    "            pl.col(\"*\"),\n",
    "            pl.col([\"aid\"])\n",
    "            .apply(apply_covisit_clicks_feature)\n",
    "            .over(\"session\")\n",
    "            .alias(\"covisit_clicks_feature\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# number of clicks in a session at each timestamp\n",
    "def add_click_num_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.when(pl.col('type') == 0)\n",
    "          .then(pl.col('aid').cumcount().over('session'))\n",
    "          .otherwise(pl.lit(None)).alias('click_num_chrono')\n",
    "          .forward_fill()\n",
    "    ])\n",
    "\n",
    "\n",
    "# number of clicks in a session at each timestamp in reverse chronological order\n",
    "def add_click_num_reverse_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.when(pl.col('type') == 0)\n",
    "          .then(pl.col('aid').cumcount().reverse().forward_fill().over('session'))\n",
    "          .otherwise(pl.lit(None)).alias('click_num_reverse_chrono')\n",
    "          .forward_fill()\n",
    "    ])\n",
    "\n",
    "\n",
    "def add_counter(event_types):\n",
    "    cumcount, counter = [], 0\n",
    "    for event in event_types:\n",
    "        if event == 1:\n",
    "            counter += 1\n",
    "        cumcount.append(counter)\n",
    "    return cumcount\n",
    "\n",
    "\n",
    "# number of carts in a session at each timestamp\n",
    "def add_cart_num_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.when(pl.col('type') == 1)\n",
    "          .then(pl.col(['type']).apply(add_counter).forward_fill().over('session'))\n",
    "          .otherwise(pl.lit(0)).alias('cart_num_chrono')\n",
    "    ])\n",
    "\n",
    "\n",
    "# number of carts in a session at each timestamp\n",
    "def add_order_num_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.when(pl.col('type') == 2)\n",
    "          .then(pl.col(['type']).apply(add_counter).forward_fill().over('session'))\n",
    "          .otherwise(pl.lit(0)).alias('order_num_chrono')\n",
    "    ])\n",
    "\n",
    "\n",
    "# doesn't seem correct - please cross-check\n",
    "def add_aid_interacted_with_count(df):\n",
    "    temp_df = df.unique(subset=['session', 'aid'])\n",
    "    temp_df = temp_df.select([\n",
    "            pl.col('*'),\n",
    "            pl.col('session').cumcount().over('session').alias('aid_interacted_with_unique')\n",
    "        ])\n",
    "    df = df.join(temp_df, on=['session', 'aid'], how='left')\n",
    "    return df.select(pl.exclude(\"^.*right$\"))\n",
    "\n",
    "\n",
    "def add_sec_since_last_action(df):\n",
    "    return df.select(\n",
    "        [\n",
    "            pl.col(\"*\"),\n",
    "            pl.col(\"ts\")\n",
    "            .diff()\n",
    "            .over(\"session\")\n",
    "            .alias(\"seconds_since_last_action\"),\n",
    "        ]\n",
    "    ).fill_null(-1)\n",
    "\n",
    "\n",
    "def add_sec_since_first_action(df):\n",
    "    return df.select(\n",
    "        [\n",
    "            pl.col(\"*\"),\n",
    "            (pl.col(\"ts\") - pl.col(\"ts\").min())\n",
    "            .over(\"session\")\n",
    "            .alias(\"seconds_since_first_action\"),\n",
    "        ]\n",
    "    ).fill_null(-1)\n",
    "\n",
    "\n",
    "def add_sec_to_session_end(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        (pl.col('ts').max() - pl.col('ts'))\n",
    "        .over('session')\n",
    "        .alias('seconds_to_session_end')\n",
    "    ]).fill_null(-1)\n",
    "\n",
    "\n",
    "def add_action_num_reverse_chrono_unique(df):\n",
    "    temp_df = df.unique(subset=['session', 'aid'])\n",
    "    temp_df = temp_df.select([\n",
    "            pl.col('*'),\n",
    "            pl.col('session').cumcount().reverse().over('session').alias('action_num_reverse_chrono_unique')\n",
    "        ])\n",
    "    df = df.join(temp_df, on=['session', 'aid'], how='left')\n",
    "    return df.select(pl.exclude(\"^.*right$\"))\n",
    "\n",
    "\n",
    "def add_action_num_reverse_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').cumcount().reverse().over('session').alias('action_num_reverse_chrono')\n",
    "    ])\n",
    "\n",
    "\n",
    "def add_session_length(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').count().over('session').alias('session_length')\n",
    "    ])\n",
    "\n",
    "\n",
    "def add_type_weighted_log_recency_score(df):\n",
    "    type_weights = {0:0.5, 1:9, 2:0.5}\n",
    "    type_weighted_log_recency_score = pl.Series(df['log_recency_score'] / df['type'].apply(lambda x: type_weights[x]))\n",
    "    return df.with_column(type_weighted_log_recency_score.alias('type_weighted_log_recency_score'))\n",
    "\n",
    "\n",
    "def add_log_recency_score(df):\n",
    "    linear_interpolation = 0.1 + ((1-0.1) / (df['session_length']-1)) * (df['session_length']-df['action_num_reverse_chrono']-1)\n",
    "    return df.with_columns(pl.Series(2**linear_interpolation - 1).alias('log_recency_score')).fill_nan(1)\n",
    "\n",
    "\n",
    "def apply(df, pipeline):\n",
    "    for f in pipeline:\n",
    "        df = f(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "pipeline = [\n",
    "    add_covisit_clicks_feature,\n",
    "    add_click_num_chrono,\n",
    "    add_click_num_reverse_chrono,\n",
    "    add_cart_num_chrono,\n",
    "    add_order_num_chrono,\n",
    "    add_aid_interacted_with_count,\n",
    "    add_sec_since_last_action,\n",
    "    add_sec_since_first_action,\n",
    "    add_sec_to_session_end,\n",
    "    add_action_num_reverse_chrono_unique,\n",
    "    add_action_num_reverse_chrono,\n",
    "    add_session_length,\n",
    "    add_log_recency_score,\n",
    "    add_type_weighted_log_recency_score,\n",
    "    add_word2vec_feature,\n",
    "    explode_word2vec_to_columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cargobuild/anaconda3/envs/kaggle/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/cargobuild/anaconda3/envs/kaggle/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n",
      "/tmp/ipykernel_27634/1444499212.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word2vec_features = df['word2vec_feature'].apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "user_features = apply(test.head(10000), pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "<small>shape: (10, 12)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "session\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_mean\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_sum\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_max\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_min\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_std\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_var\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_median\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_q1\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_q3\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_kurtosis\n",
       "</th>\n",
       "<th>\n",
       "type_weighted_log_recency_score_count\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i32\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "11098564\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "NaN\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098676\n",
       "</td>\n",
       "<td>\n",
       "0.962832\n",
       "</td>\n",
       "<td>\n",
       "15.405305\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.018304\n",
       "</td>\n",
       "<td>\n",
       "0.615807\n",
       "</td>\n",
       "<td>\n",
       "0.379218\n",
       "</td>\n",
       "<td>\n",
       "0.928804\n",
       "</td>\n",
       "<td>\n",
       "0.531513\n",
       "</td>\n",
       "<td>\n",
       "1.530812\n",
       "</td>\n",
       "<td>\n",
       "-1.117153\n",
       "</td>\n",
       "<td>\n",
       "16\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098669\n",
       "</td>\n",
       "<td>\n",
       "0.995082\n",
       "</td>\n",
       "<td>\n",
       "5.970491\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.143547\n",
       "</td>\n",
       "<td>\n",
       "0.695332\n",
       "</td>\n",
       "<td>\n",
       "0.483487\n",
       "</td>\n",
       "<td>\n",
       "0.933871\n",
       "</td>\n",
       "<td>\n",
       "0.42839\n",
       "</td>\n",
       "<td>\n",
       "1.530812\n",
       "</td>\n",
       "<td>\n",
       "-1.218815\n",
       "</td>\n",
       "<td>\n",
       "6\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098607\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "NaN\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098551\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "NaN\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098639\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "NaN\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098606\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "NaN\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098739\n",
       "</td>\n",
       "<td>\n",
       "0.995082\n",
       "</td>\n",
       "<td>\n",
       "5.970491\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.143547\n",
       "</td>\n",
       "<td>\n",
       "0.695332\n",
       "</td>\n",
       "<td>\n",
       "0.483487\n",
       "</td>\n",
       "<td>\n",
       "0.933871\n",
       "</td>\n",
       "<td>\n",
       "0.42839\n",
       "</td>\n",
       "<td>\n",
       "1.530812\n",
       "</td>\n",
       "<td>\n",
       "-1.218815\n",
       "</td>\n",
       "<td>\n",
       "6\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098615\n",
       "</td>\n",
       "<td>\n",
       "0.535671\n",
       "</td>\n",
       "<td>\n",
       "2.142683\n",
       "</td>\n",
       "<td>\n",
       "1.24901\n",
       "</td>\n",
       "<td>\n",
       "0.111111\n",
       "</td>\n",
       "<td>\n",
       "0.533399\n",
       "</td>\n",
       "<td>\n",
       "0.284515\n",
       "</td>\n",
       "<td>\n",
       "0.391281\n",
       "</td>\n",
       "<td>\n",
       "0.143547\n",
       "</td>\n",
       "<td>\n",
       "1.24901\n",
       "</td>\n",
       "<td>\n",
       "-1.269535\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "11098595\n",
       "</td>\n",
       "<td>\n",
       "0.978408\n",
       "</td>\n",
       "<td>\n",
       "38.157907\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "0.143547\n",
       "</td>\n",
       "<td>\n",
       "0.555597\n",
       "</td>\n",
       "<td>\n",
       "0.308688\n",
       "</td>\n",
       "<td>\n",
       "0.928171\n",
       "</td>\n",
       "<td>\n",
       "0.484849\n",
       "</td>\n",
       "<td>\n",
       "1.450588\n",
       "</td>\n",
       "<td>\n",
       "-1.148419\n",
       "</td>\n",
       "<td>\n",
       "39\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (10, 12)\n",
       "┌──────────┬────────────┬────────────┬────────────┬─────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ session  ┆ type_weigh ┆ type_weigh ┆ type_weigh ┆ ... ┆ type_weigh ┆ type_weigh ┆ type_weigh ┆ type_weigh │\n",
       "│ ---      ┆ ted_log_re ┆ ted_log_re ┆ ted_log_re ┆     ┆ ted_log_re ┆ ted_log_re ┆ ted_log_re ┆ ted_log_re │\n",
       "│ i32      ┆ cency_scor ┆ cency_scor ┆ cency_scor ┆     ┆ cency_scor ┆ cency_scor ┆ cency_scor ┆ cency_scor │\n",
       "│          ┆ e_...      ┆ e_...      ┆ e_...      ┆     ┆ e_...      ┆ e_...      ┆ e_...      ┆ e_...      │\n",
       "│          ┆ ---        ┆ ---        ┆ ---        ┆     ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│          ┆ f64        ┆ f64        ┆ f64        ┆     ┆ f64        ┆ f64        ┆ f64        ┆ u32        │\n",
       "╞══════════╪════════════╪════════════╪════════════╪═════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 11098564 ┆ 2.0        ┆ 2.0        ┆ 2.0        ┆ ... ┆ 2.0        ┆ 2.0        ┆ NaN        ┆ 1          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098676 ┆ 0.962832   ┆ 15.405305  ┆ 2.0        ┆ ... ┆ 0.531513   ┆ 1.530812   ┆ -1.117153  ┆ 16         │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098669 ┆ 0.995082   ┆ 5.970491   ┆ 2.0        ┆ ... ┆ 0.42839    ┆ 1.530812   ┆ -1.218815  ┆ 6          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098607 ┆ 2.0        ┆ 2.0        ┆ 2.0        ┆ ... ┆ 2.0        ┆ 2.0        ┆ NaN        ┆ 1          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...      ┆ ...        ┆ ...        ┆ ...        ┆ ... ┆ ...        ┆ ...        ┆ ...        ┆ ...        │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098606 ┆ 2.0        ┆ 2.0        ┆ 2.0        ┆ ... ┆ 2.0        ┆ 2.0        ┆ NaN        ┆ 1          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098739 ┆ 0.995082   ┆ 5.970491   ┆ 2.0        ┆ ... ┆ 0.42839    ┆ 1.530812   ┆ -1.218815  ┆ 6          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098615 ┆ 0.535671   ┆ 2.142683   ┆ 1.24901    ┆ ... ┆ 0.143547   ┆ 1.24901    ┆ -1.269535  ┆ 4          │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 11098595 ┆ 0.978408   ┆ 38.157907  ┆ 2.0        ┆ ... ┆ 0.484849   ┆ 1.450588   ┆ -1.148419  ┆ 39         │\n",
       "└──────────┴────────────┴────────────┴────────────┴─────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_features.groupby('session').agg([\n",
    "#     pl.col('type_weighted_log_recency_score').mean().alias('type_weighted_log_recency_score_mean'),\n",
    "#     pl.col('type_weighted_log_recency_score').sum().alias('type_weighted_log_recency_score_sum'),\n",
    "#     pl.col('type_weighted_log_recency_score').max().alias('type_weighted_log_recency_score_max'),\n",
    "#     pl.col('type_weighted_log_recency_score').min().alias('type_weighted_log_recency_score_min'),\n",
    "#     pl.col('type_weighted_log_recency_score').std().alias('type_weighted_log_recency_score_std'),\n",
    "#     pl.col('type_weighted_log_recency_score').var().alias('type_weighted_log_recency_score_var'),\n",
    "#     pl.col('type_weighted_log_recency_score').median().alias('type_weighted_log_recency_score_median'),\n",
    "#     pl.col('type_weighted_log_recency_score').quantile(0.25).alias('type_weighted_log_recency_score_q1'),\n",
    "#     pl.col('type_weighted_log_recency_score').quantile(0.75).alias('type_weighted_log_recency_score_q3'),\n",
    "#     pl.col('type_weighted_log_recency_score').kurtosis().alias('type_weighted_log_recency_score_kurtosis'),\n",
    "#     pl.col('type_weighted_log_recency_score').count().alias('type_weighted_log_recency_score_count'),\n",
    "# ]).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb7d3506f6b9ec02b64e3bf4f1192f2c202eabfa04777042b4cf2d3aa9ab065c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
