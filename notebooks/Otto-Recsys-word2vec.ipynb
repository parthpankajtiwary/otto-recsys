{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import polars as pl\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    data_path = \"../data/\"\n",
    "    local_validation = False\n",
    "    debug = False\n",
    "    validation_path = \"../data/local_validation/\"\n",
    "    train_file = \"train.parquet\"\n",
    "    test_file = \"test.parquet\"\n",
    "    test_labels_file = \"test_labels.parquet\"\n",
    "    submission_path = \"submissions/\"\n",
    "    submission_file = \"submission_{:%Y-%m-%d_%H-%M}.csv\"\n",
    "    type_labels = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "    type_weight = {0: 1, 1: 6, 2: 3}\n",
    "    version = 1\n",
    "    chunk_size = 100_000\n",
    "    random_state = 42\n",
    "    fraction = 0.02\n",
    "    n_samples = 30\n",
    "    n_top = 15\n",
    "    diff_clicks = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: data/train.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mread_parquet(config\u001b[39m.\u001b[39;49mdata_path \u001b[39m+\u001b[39;49m config\u001b[39m.\u001b[39;49mtrain_file)\n\u001b[1;32m      2\u001b[0m test \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mread_parquet(config\u001b[39m.\u001b[39mdata_path \u001b[39m+\u001b[39m config\u001b[39m.\u001b[39mtest_file)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/polars/utils.py:329\u001b[0m, in \u001b[0;36mdeprecated_alias.<locals>.deco.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m    327\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    328\u001b[0m     _rename_kwargs(fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, kwargs, aliases)\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/polars/io.py:973\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, use_pyarrow, memory_map, storage_options, parallel, row_count_name, row_count_offset, low_memory, pyarrow_options)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    962\u001b[0m         DataFrame,\n\u001b[1;32m    963\u001b[0m         from_arrow(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m         ),\n\u001b[1;32m    971\u001b[0m     )\n\u001b[0;32m--> 973\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame\u001b[39m.\u001b[39;49m_read_parquet(\n\u001b[1;32m    974\u001b[0m     source_prep,\n\u001b[1;32m    975\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    976\u001b[0m     n_rows\u001b[39m=\u001b[39;49mn_rows,\n\u001b[1;32m    977\u001b[0m     parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[1;32m    978\u001b[0m     row_count_name\u001b[39m=\u001b[39;49mrow_count_name,\n\u001b[1;32m    979\u001b[0m     row_count_offset\u001b[39m=\u001b[39;49mrow_count_offset,\n\u001b[1;32m    980\u001b[0m     low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[1;32m    981\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/polars/internals/dataframe/frame.py:678\u001b[0m, in \u001b[0;36mDataFrame._read_parquet\u001b[0;34m(cls, file, columns, n_rows, parallel, row_count_name, row_count_offset, low_memory)\u001b[0m\n\u001b[1;32m    676\u001b[0m projection, columns \u001b[39m=\u001b[39m handle_projection_columns(columns)\n\u001b[1;32m    677\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df \u001b[39m=\u001b[39m PyDataFrame\u001b[39m.\u001b[39;49mread_parquet(\n\u001b[1;32m    679\u001b[0m     file,\n\u001b[1;32m    680\u001b[0m     columns,\n\u001b[1;32m    681\u001b[0m     projection,\n\u001b[1;32m    682\u001b[0m     n_rows,\n\u001b[1;32m    683\u001b[0m     parallel,\n\u001b[1;32m    684\u001b[0m     _prepare_row_count_args(row_count_name, row_count_offset),\n\u001b[1;32m    685\u001b[0m     low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: data/train.parquet"
     ]
    }
   ],
   "source": [
    "train = pl.read_parquet(config.data_path + config.train_file)\n",
    "test = pl.read_parquet(config.data_path + config.test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = (\n",
    "    pl.concat([train, test]).groupby(\"session\").agg(pl.col(\"aid\").alias(\"sentence\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences_df[\"sentence\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/gensim/models/word2vec.py:427\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, passes\u001b[39m=\u001b[39m(epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m    426\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_vocab(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, trim_rule\u001b[39m=\u001b[39mtrim_rule)\n\u001b[0;32m--> 427\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    428\u001b[0m         corpus_iterable\u001b[39m=\u001b[39;49mcorpus_iterable, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_count,\n\u001b[1;32m    429\u001b[0m         total_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_total_words, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m    430\u001b[0m         end_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_alpha, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m    431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[39mif\u001b[39;00m trim_rule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/gensim/models/word2vec.py:1070\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     callback\u001b[39m.\u001b[39mon_epoch_begin(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1069\u001b[0m \u001b[39mif\u001b[39;00m corpus_iterable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1070\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(\n\u001b[1;32m   1071\u001b[0m         corpus_iterable, cur_epoch\u001b[39m=\u001b[39;49mcur_epoch, total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[1;32m   1072\u001b[0m         total_words\u001b[39m=\u001b[39;49mtotal_words, queue_factor\u001b[39m=\u001b[39;49mqueue_factor, report_delay\u001b[39m=\u001b[39;49mreport_delay,\n\u001b[1;32m   1073\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1074\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch_corpusfile(\n\u001b[1;32m   1076\u001b[0m         corpus_file, cur_epoch\u001b[39m=\u001b[39mcur_epoch, total_examples\u001b[39m=\u001b[39mtotal_examples, total_words\u001b[39m=\u001b[39mtotal_words,\n\u001b[1;32m   1077\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/gensim/models/word2vec.py:1431\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     thread\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m-> 1431\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_epoch_progress(\n\u001b[1;32m   1432\u001b[0m     progress_queue, job_queue, cur_epoch\u001b[39m=\u001b[39;49mcur_epoch, total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[1;32m   1433\u001b[0m     total_words\u001b[39m=\u001b[39;49mtotal_words, report_delay\u001b[39m=\u001b[39;49mreport_delay, is_corpus_file_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1434\u001b[0m )\n\u001b[1;32m   1436\u001b[0m \u001b[39mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/site-packages/gensim/models/word2vec.py:1286\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1283\u001b[0m unfinished_worker_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\n\u001b[1;32m   1285\u001b[0m \u001b[39mwhile\u001b[39;00m unfinished_worker_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1286\u001b[0m     report \u001b[39m=\u001b[39m progress_queue\u001b[39m.\u001b[39;49mget()  \u001b[39m# blocks if workers too slow\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[39mif\u001b[39;00m report \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# a thread reporting that it finished\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         unfinished_worker_count \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    sentences=sentences, vector_size=50, window=20, negative=10, workers=4\n",
    ")\n",
    "word2vec.save(\"word2vec-windowsize-20-sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 27s, sys: 1min 24s, total: 7min 51s\n",
      "Wall time: 24.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "aid2idx = {aid: i for i, aid in enumerate(word2vec.wv.index_to_key)}\n",
    "index = AnnoyIndex(10, \"euclidean\")\n",
    "\n",
    "for aid, idx in aid2idx.items():\n",
    "    index.add_item(idx, word2vec.wv.vectors[idx])\n",
    "\n",
    "index.build(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_types = [\"clicks\", \"carts\", \"orders\"]\n",
    "test_session_products = (\n",
    "    test.to_pandas().reset_index(drop=True).groupby(\"session\")[\"aid\"].apply(list)\n",
    ")\n",
    "test_session_types = (\n",
    "    test.to_pandas().reset_index(drop=True).groupby(\"session\")[\"type\"].apply(list)\n",
    ")\n",
    "\n",
    "labels = []\n",
    "\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11830] [0] [884502, 1732105, 87442, 1633746, 1125638, 487136, 432989, 1182614, 807298, 876129, 582732, 588923, 1134980, 1481487, 146086, 409620, 517826, 825072, 135833, 1344942]\n"
     ]
    }
   ],
   "source": [
    "for products, types in zip(test_session_products, test_session_types):\n",
    "    products = list(dict.fromkeys(products[::-1]))\n",
    "\n",
    "    most_recent_product = products[0]\n",
    "\n",
    "    nns = [\n",
    "        word2vec.wv.index_to_key[i]\n",
    "        for i in index.get_nns_by_item(aid2idx[most_recent_product], 21)[1:]\n",
    "    ]\n",
    "\n",
    "    print(products, types, nns)\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15824f91cc7b75e025d2367af0109417504b30ad993611e7f5b39069152fd433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
