{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import cudf, itertools\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    data_path = '../data/'\n",
    "    local_validation = True\n",
    "    validation_path = '../data/local_validation/'\n",
    "    train_file = 'train.parquet'\n",
    "    test_file = 'test.parquet'\n",
    "    test_labels_file = 'test_labels.parquet'\n",
    "    n_session_samples = 100\n",
    "    n_most_common = 50\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.local_validation:\n",
    "    train = cudf.read_parquet(config.validation_path + config.train_file)\n",
    "    test = pd.read_parquet(config.validation_path + config.test_file)\n",
    "    test_labels = cudf.read_parquet(config.validation_path + config.test_labels_file)\n",
    "    data = cudf.concat([train])\n",
    "else:\n",
    "    train = cudf.read_parquet(config.data_path + config.train_file)\n",
    "    test = cudf.read_parquet(config.data_path + config.test_file)\n",
    "    data = cudf.concat([train, test])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    data = data.sample(frac=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "type_weight = {0:1, 1:6, 2:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create co-visitation matrix on GPU using CuDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carts Orders Co-visitation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:48<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "version = 1\n",
    "data_copy = data.copy()\n",
    "data_copy = data_copy.set_index('session')\n",
    "sessions = data_copy.index.unique()\n",
    "\n",
    "chunk_size = 100_000\n",
    "\n",
    "tmp = list()\n",
    "for i in tqdm(range(0, sessions.shape[0], chunk_size)):\n",
    "    df = data_copy.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index()\n",
    "    df = df.sort_values(['session','ts'],ascending=[True, False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    # take only the first 30 rows (tail) of each session\n",
    "    df = df.loc[df.n<30].drop('n', axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    df['wgt'] = df.type_y.map(type_weight)\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    # aid_x is the source, aid_y is the target\n",
    "    # calculate the sum of weights based on target type\n",
    "    # we sum the weights of all the edges from same source to target\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "\n",
    "    tmp.append(df.reset_index())\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "tmp = list(map(lambda x: x.to_pandas(), tmp))\n",
    "tmp = pd.concat(tmp)\n",
    "\n",
    "# CONVERT MATRIX TO DICTIONARY\n",
    "tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "# SAVE TOP 40\n",
    "tmp = tmp.reset_index(drop=True)\n",
    "tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "# we only select 15 products for each aid_x\n",
    "tmp = tmp.loc[tmp.n<50].drop('n',axis=1)\n",
    "# SAVE TO DISK\n",
    "df = tmp.groupby('aid_x').aid_y.apply(list)\n",
    "with open(config.data_path + f'top_15_carts_orders_v{version}.pkl', 'wb') as f:\n",
    "    pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buy2Buy Co-visitation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:31<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "data_copy = data.copy()\n",
    "data_copy = data_copy.set_index('session')\n",
    "sessions = data_copy.index.unique()\n",
    "\n",
    "chunk_size = 100_000\n",
    "\n",
    "tmp = list()\n",
    "for i in tqdm(range(0, sessions.shape[0], chunk_size)):\n",
    "    df = data_copy.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index()\n",
    "    df = df.loc[(df['type']==1)|(df['type']==2)]\n",
    "\n",
    "    df = df.sort_values(['session','ts'], ascending=[True, False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df, on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs() < 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    df['wgt'] = 1\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "\n",
    "    tmp.append(df.reset_index())\n",
    "       \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "tmp = list(map(lambda x: x.to_pandas(), tmp))\n",
    "tmp = pd.concat(tmp)\n",
    "# CONVERT MATRIX TO DICTIONARY\n",
    "tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "# SAVE TOP 15\n",
    "tmp = tmp.reset_index(drop=True)\n",
    "tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "tmp = tmp.loc[tmp.n<50].drop('n',axis=1)\n",
    "# SAVE TO DISK\n",
    "df = tmp.groupby('aid_x').aid_y.apply(list)\n",
    "with open(config.data_path + f'top_15_buy2buy_v{version}.pkl', 'wb') as f:\n",
    "    pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks Co-visitation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/111 [01:33<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "data_copy = data.copy()\n",
    "data_copy = data_copy.set_index('session')\n",
    "sessions = data_copy.index.unique()\n",
    "\n",
    "chunk_size = 100_000\n",
    "\n",
    "tmp = list()\n",
    "for i in tqdm(range(0, sessions.shape[0], chunk_size)):\n",
    "    df = data_copy.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index()\n",
    "    df = df.sort_values(['session','ts'], ascending=[True, False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "\n",
    "    tmp.append(df.reset_index())\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "tmp = list(map(lambda x: x.to_pandas(), tmp))\n",
    "tmp = pd.concat(tmp)\n",
    "# CONVERT MATRIX TO DICTIONARY\n",
    "tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "# SAVE TOP 40\n",
    "tmp = tmp.reset_index(drop=True)\n",
    "tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "tmp = tmp.loc[tmp.n<50].drop('n',axis=1)\n",
    "# SAVE TO DISK\n",
    "df = tmp.groupby('aid_x').aid_y.apply(list)\n",
    "with open(config.data_path + f'top_20_clicks_v{version}.pkl', 'wb') as f:\n",
    "    pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks: 1788152\n",
      "carts: 1788152\n",
      "buy2buy: 1033926\n",
      "CPU times: user 12.6 s, sys: 1.08 s, total: 13.6 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_20_clicks = pd.read_pickle(config.data_path + f'top_20_clicks_v{version}.pkl')\n",
    "top_15_buys = pd.read_pickle(config.data_path + f'top_15_carts_orders_v{version}.pkl')\n",
    "top_15_buy2buy = pd.read_pickle(config.data_path + f'top_15_buy2buy_v{version}.pkl')\n",
    "\n",
    "# TOP CLICKS AND ORDERS IN TEST\n",
    "top_clicks = test.loc[test['type']==type_labels['clicks'],'aid'].value_counts().index.values[:20]\n",
    "top_orders = test.loc[test['type']==type_labels['orders'],'aid'].value_counts().index.values[:20]\n",
    "\n",
    "# print shape of each matrix\n",
    "print(f'clicks: {len(top_20_clicks)}')\n",
    "print(f'carts: {len(top_15_buys)}')\n",
    "print(f'buy2buy: {len(top_15_buy2buy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_clicks(df, top_20_clicks, top_clicks):\n",
    "    products = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_products = list(dict.fromkeys(products[::-1] ))\n",
    "\n",
    "    if len(unique_products) >= 20:\n",
    "        weights = np.logspace(0.1, 1, len(products), base=2, endpoint=True) - 1\n",
    "        products_tmp = Counter()\n",
    "\n",
    "        for product, weight, _type in zip(products, weights, types):\n",
    "            products_tmp[product] += weight * type_weight[_type]\n",
    "        \n",
    "        sorted_products = [product for product, _ in products_tmp.most_common(50)]\n",
    "        return sorted_products\n",
    "    else:\n",
    "        products_1 = list(itertools.chain(*[top_20_clicks[product] \\\n",
    "                        for product in unique_products if product in top_20_clicks]))\n",
    "        top_products_1 = [product for product, _ in Counter(products_1).most_common(50) \\\n",
    "                        if product not in unique_products]\n",
    "        result = unique_products + top_products_1[:20 - len(unique_products)]\n",
    "        return result + list(top_clicks[:20 - len(result)])\n",
    "\n",
    "def suggest_buys(df, top_15_buy2buy, top_15_buys, top_orders):\n",
    "    products = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    # filter df for type 1 and 2\n",
    "    unique_products = list(dict.fromkeys(products[::-1] ))\n",
    "    df = df.loc[(df['type']==1)|(df['type']==2)]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "\n",
    "    if len(unique_products) >= 20:\n",
    "        weights = np.logspace(0.5, 1, len(products), base=2, endpoint=True) - 1\n",
    "        products_tmp = Counter()\n",
    "        for product, weight, _type in zip(products, weights, types):\n",
    "            products_tmp[product] += weight * type_weight[_type]\n",
    "        products_1 = list(itertools.chain(*[top_15_buy2buy.get(product, []) \\\n",
    "                        for product in unique_buys if product in top_15_buy2buy]))\n",
    "        for product in products_1: products_tmp[product] += 0.1\n",
    "        sorted_products = [product for product, _ in products_tmp.most_common(50)]\n",
    "        return sorted_products\n",
    "    else:\n",
    "        products_1 = list(itertools.chain(*[top_15_buys.get(product, []) \\\n",
    "                          for product in unique_products if product in top_15_buys]))\n",
    "        products_2 = list(itertools.chain(*[top_15_buy2buy.get(product, []) \\\n",
    "                          for product in unique_buys if product in top_15_buy2buy]))\n",
    "        top_products = [product for product, _ in Counter(products_1 + products_2).most_common(50) \\\n",
    "                        if product not in unique_products]\n",
    "        result = unique_products + top_products[:20 - len(unique_products)]\n",
    "        return result + list(top_orders[:20 - len(result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1801251/1801251 [02:26<00:00, 12307.89it/s]\n",
      "100%|██████████| 1801251/1801251 [10:51<00:00, 2764.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 24s, sys: 25.3 s, total: 13min 50s\n",
      "Wall time: 13min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not config.local_validation:\n",
    "    test = test.to_pandas()\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pred_df_clicks = test.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).progress_apply(\n",
    "    lambda x: suggest_clicks(x, top_20_clicks, top_clicks)\n",
    ")\n",
    "\n",
    "pred_df_buys = test.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).progress_apply(\n",
    "    lambda x: suggest_buys(x, top_15_buy2buy, top_15_buys, top_orders)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parthtiwary/anaconda3/envs/kaggle/lib/python3.9/site-packages/pandarallel/data_types/series.py:16: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c733baaa8b42aeb5b72ebdb1ec55ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=540376), Label(value='0 / 540376')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>11830 588923 884502 1732105 1157882 571762 231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029 1647167 217742 1666485 1715900 13552 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 1603001 583026 254154 963957 877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>396199 1271998 452188 1728212 1365569 624163 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>876469 7651 108125 77906 1159379 1202618 17040...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_clicks  11830 588923 884502 1732105 1157882 571762 231...\n",
       "1  11098529_clicks  1105029 1647167 217742 1666485 1715900 13552 1...\n",
       "2  11098530_clicks  409236 264500 1603001 583026 254154 963957 877...\n",
       "3  11098531_clicks  396199 1271998 452188 1728212 1365569 624163 1...\n",
       "4  11098532_clicks  876469 7651 108125 77906 1159379 1202618 17040..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.parallel_apply(lambda x: \" \".join(map(str,x)))\n",
    "pred_df.to_csv(config.data_path + 'submission.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c552c32d3364dc390e2382b959e1d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c92db30fcc43a2aef38c3fed46e965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e061a1c2024a04bae303cf022de74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=175554), Label(value='0 / 175554')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks recall = 0.4745980425329273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59af2d790fd64bd997e3474fe9aa7956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba16a6031b64c2eb1a796c91572cdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed278d8e685d4dc684ca868e405d1c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=30635), Label(value='0 / 30635')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carts recall = 0.3916392879569527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc493952ee184bd7b45761f728bfe5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e82390a0a2240a99f52d5c672f2df52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=180126), Label(value='0 / 180126')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb97da4cfce7400ab533484d20963c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=15082), Label(value='0 / 15082')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders recall = 0.6406705329984073\n",
      "=============\n",
      "Overall Recall = 0.5493539104394228\n",
      "=============\n",
      "CPU times: user 26.3 s, sys: 13.8 s, total: 40.1 s\n",
      "Wall time: 45.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# COMPUTE METRIC\n",
    "\n",
    "if config.local_validation:\n",
    "    score = 0\n",
    "    weights = {'clicks': 0.10, 'carts': 0.30, 'orders': 0.60}\n",
    "    for t in ['clicks','carts','orders']:\n",
    "        sub = pred_df.loc[pred_df.session_type.str.contains(t)].copy()\n",
    "        sub['session'] = sub.session_type.parallel_apply(lambda x: int(x.split('_')[0]))\n",
    "        sub.labels = sub.labels.parallel_apply(lambda x: [int(i) for i in x.split(' ')[:20]])\n",
    "        test_labels = pd.read_parquet(config.validation_path + 'test_labels.parquet')\n",
    "        test_labels = test_labels.loc[test_labels['type']==t]\n",
    "        test_labels = test_labels.merge(sub, how='left', on=['session'])\n",
    "        test_labels['hits'] = test_labels.parallel_apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "        recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "        score += weights[t]*recall\n",
    "        print(f'{t} recall =',recall)\n",
    "        \n",
    "    print('=============')\n",
    "    print('Overall Recall =',score)\n",
    "    print('=============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clicks\n",
    "- 0.461\n",
    "- 0.474 (current parameters - clicks)\n",
    "### Carts\n",
    "- 0.376\n",
    "### Orders\n",
    "- 0.632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15824f91cc7b75e025d2367af0109417504b30ad993611e7f5b39069152fd433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
